{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suPoI511rXmJ"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4162,
     "status": "ok",
     "timestamp": 1747569714802,
     "user": {
      "displayName": "Sofia Di Lucia",
      "userId": "06755773150031550415"
     },
     "user_tz": -120
    },
    "id": "xoeq82R92KtP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "  def __init__(self, input_dim, h_dim, z_dim):\n",
    "    super().__init__()\n",
    "    # encoder\n",
    "    self.img_2hid = nn.Linear(input_dim, h_dim)\n",
    "    self.hid_2mu = nn.Linear(h_dim, z_dim)\n",
    "    self.hid_2sigma = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    # decoder\n",
    "    self.z_2hid = nn.Linear(z_dim, h_dim)\n",
    "    self.hid_2img = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "    self.relu = nn.ReLU()                                 # activation func in hidden layers\n",
    "\n",
    "  def encode(self, x):\n",
    "    h = self.relu(self.img_2hid(x))\n",
    "    mu, sigma = self.hid_2mu(h), self.hid_2sigma(h)\n",
    "    return mu, sigma\n",
    "\n",
    "  def decode(self, z):\n",
    "    h = self.relu(self.z_2hid(z))\n",
    "    return self.hid_2img(h)\n",
    "\n",
    "  def forward(self, x):\n",
    "    mu, sigma = self.encode(x)\n",
    "    epsilon = torch.randn_like(sigma)\n",
    "    z_new = mu + sigma*epsilon                            # reparameterization trick\n",
    "    x_reconstructed = self.decode(z_new)\n",
    "    return x_reconstructed, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luca experiments (representing data by hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy surplus / deficit by Noemi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 06:00:00+00:00</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 09:00:00+00:00</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 12:00:00+00:00</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2024-12-31 09:00:00+00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2024-12-31 12:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>2024-12-31 15:00:00+00:00</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>2024-12-31 18:00:00+00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>2024-12-31 21:00:00+00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     timestamp  sign\n",
       "0    2022-01-01 00:00:00+00:00   -12\n",
       "1    2022-01-01 03:00:00+00:00   -12\n",
       "2    2022-01-01 06:00:00+00:00   -12\n",
       "3    2022-01-01 09:00:00+00:00   -12\n",
       "4    2022-01-01 12:00:00+00:00   -12\n",
       "...                        ...   ...\n",
       "8763 2024-12-31 09:00:00+00:00    12\n",
       "8764 2024-12-31 12:00:00+00:00    10\n",
       "8765 2024-12-31 15:00:00+00:00    -2\n",
       "8766 2024-12-31 18:00:00+00:00     8\n",
       "8767 2024-12-31 21:00:00+00:00     6\n",
       "\n",
       "[8768 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"lcpb_files/sbil.zst\"\n",
    "class_data = pd.read_parquet(filename)\n",
    "\n",
    "# sel NORD\n",
    "class_data = class_data[class_data['macrozone'] == 'NORD']\n",
    "# take timestamp and set as index\n",
    "class_data['timestamp'] = (class_data['date_time'])\n",
    "class_data = class_data.set_index('timestamp')\n",
    "# resample every 3h\n",
    "resampled = class_data.resample('3h').agg({'sign': 'sum'}) # lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan})\n",
    "resampled = resampled.reset_index()\n",
    "\n",
    "# remove 2025\n",
    "resampled = resampled[resampled['timestamp'].dt.year != 2025]\n",
    "\n",
    "resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_t0</th>\n",
       "      <th>2t_t0</th>\n",
       "      <th>solar_t0</th>\n",
       "      <th>tp_t0</th>\n",
       "      <th>ws_10m_t0</th>\n",
       "      <th>ws_100m_t0</th>\n",
       "      <th>hour_sin_t0</th>\n",
       "      <th>hour_cos_t0</th>\n",
       "      <th>day_sin_t0</th>\n",
       "      <th>day_cos_t0</th>\n",
       "      <th>...</th>\n",
       "      <th>ws_100m_t8</th>\n",
       "      <th>hour_sin_t8</th>\n",
       "      <th>hour_cos_t8</th>\n",
       "      <th>day_sin_t8</th>\n",
       "      <th>day_cos_t8</th>\n",
       "      <th>month_sin_t8</th>\n",
       "      <th>month_cos_t8</th>\n",
       "      <th>sin_dayofyear_t8</th>\n",
       "      <th>cos_dayofyear_t8</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224855</td>\n",
       "      <td>-1.266622</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.540314</td>\n",
       "      <td>-0.169929</td>\n",
       "      <td>0.237315</td>\n",
       "      <td>0.249009</td>\n",
       "      <td>1.890047</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132097</td>\n",
       "      <td>-0.685682</td>\n",
       "      <td>1.408711</td>\n",
       "      <td>0.280448</td>\n",
       "      <td>1.400505</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.025586</td>\n",
       "      <td>1.291842</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.224855</td>\n",
       "      <td>-1.324489</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.540314</td>\n",
       "      <td>-0.167036</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>1.183829</td>\n",
       "      <td>1.408519</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.931334</td>\n",
       "      <td>0.249115</td>\n",
       "      <td>1.890286</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>1.314595</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>1.291222</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.224855</td>\n",
       "      <td>-1.363120</td>\n",
       "      <td>-0.691746</td>\n",
       "      <td>-0.543042</td>\n",
       "      <td>-0.218606</td>\n",
       "      <td>-0.093139</td>\n",
       "      <td>1.571044</td>\n",
       "      <td>0.246007</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778698</td>\n",
       "      <td>1.183912</td>\n",
       "      <td>1.408711</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>1.314595</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>1.291222</td>\n",
       "      <td>2022-01-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224855</td>\n",
       "      <td>-1.091436</td>\n",
       "      <td>0.355950</td>\n",
       "      <td>-0.543042</td>\n",
       "      <td>-0.396948</td>\n",
       "      <td>-0.530006</td>\n",
       "      <td>1.183829</td>\n",
       "      <td>-0.916506</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664870</td>\n",
       "      <td>1.571118</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>1.314595</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>1.291222</td>\n",
       "      <td>2022-01-01 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.224855</td>\n",
       "      <td>-0.496955</td>\n",
       "      <td>0.545301</td>\n",
       "      <td>-0.543042</td>\n",
       "      <td>-0.719834</td>\n",
       "      <td>-0.962998</td>\n",
       "      <td>0.249009</td>\n",
       "      <td>-1.398034</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452988</td>\n",
       "      <td>1.183912</td>\n",
       "      <td>-0.916535</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>1.314595</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>1.291222</td>\n",
       "      <td>2022-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>1.224561</td>\n",
       "      <td>-0.453550</td>\n",
       "      <td>-0.478673</td>\n",
       "      <td>-0.546437</td>\n",
       "      <td>-1.220757</td>\n",
       "      <td>-1.408609</td>\n",
       "      <td>-0.685811</td>\n",
       "      <td>-0.916506</td>\n",
       "      <td>-0.287572</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.518295</td>\n",
       "      <td>0.249115</td>\n",
       "      <td>-1.398110</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>1.429539</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>1.295919</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.292048</td>\n",
       "      <td>2024-12-30 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>1.224561</td>\n",
       "      <td>-1.110274</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.545773</td>\n",
       "      <td>-1.125086</td>\n",
       "      <td>-1.549938</td>\n",
       "      <td>-1.073026</td>\n",
       "      <td>0.246007</td>\n",
       "      <td>-0.287572</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.388240</td>\n",
       "      <td>-0.685682</td>\n",
       "      <td>-0.916535</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>1.429539</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>1.295919</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.292048</td>\n",
       "      <td>2024-12-30 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8317</th>\n",
       "      <td>1.224561</td>\n",
       "      <td>-1.110274</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.545773</td>\n",
       "      <td>-1.125086</td>\n",
       "      <td>-1.549938</td>\n",
       "      <td>-1.073026</td>\n",
       "      <td>0.246007</td>\n",
       "      <td>-0.287572</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.439442</td>\n",
       "      <td>-1.072887</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>1.429539</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>1.295919</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.292048</td>\n",
       "      <td>2024-12-30 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>1.224561</td>\n",
       "      <td>-1.322641</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.545773</td>\n",
       "      <td>-1.180936</td>\n",
       "      <td>-1.527834</td>\n",
       "      <td>-0.685811</td>\n",
       "      <td>1.408519</td>\n",
       "      <td>-0.287572</td>\n",
       "      <td>1.400589</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.439442</td>\n",
       "      <td>-1.072887</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>1.429539</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>1.295919</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.292048</td>\n",
       "      <td>2024-12-30 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>1.224561</td>\n",
       "      <td>-1.478596</td>\n",
       "      <td>-0.785197</td>\n",
       "      <td>-0.545773</td>\n",
       "      <td>-0.692463</td>\n",
       "      <td>-0.719948</td>\n",
       "      <td>0.249009</td>\n",
       "      <td>1.890047</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>1.429623</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.435642</td>\n",
       "      <td>-0.685682</td>\n",
       "      <td>1.408711</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>1.429539</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>1.295919</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.292048</td>\n",
       "      <td>2024-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8320 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_t0     2t_t0  solar_t0     tp_t0  ws_10m_t0  ws_100m_t0  \\\n",
       "0    -1.224855 -1.266622 -0.785197 -0.540314  -0.169929    0.237315   \n",
       "1    -1.224855 -1.324489 -0.785197 -0.540314  -0.167036    0.001132   \n",
       "2    -1.224855 -1.363120 -0.691746 -0.543042  -0.218606   -0.093139   \n",
       "3    -1.224855 -1.091436  0.355950 -0.543042  -0.396948   -0.530006   \n",
       "4    -1.224855 -0.496955  0.545301 -0.543042  -0.719834   -0.962998   \n",
       "...        ...       ...       ...       ...        ...         ...   \n",
       "8315  1.224561 -0.453550 -0.478673 -0.546437  -1.220757   -1.408609   \n",
       "8316  1.224561 -1.110274 -0.785197 -0.545773  -1.125086   -1.549938   \n",
       "8317  1.224561 -1.110274 -0.785197 -0.545773  -1.125086   -1.549938   \n",
       "8318  1.224561 -1.322641 -0.785197 -0.545773  -1.180936   -1.527834   \n",
       "8319  1.224561 -1.478596 -0.785197 -0.545773  -0.692463   -0.719948   \n",
       "\n",
       "      hour_sin_t0  hour_cos_t0  day_sin_t0  day_cos_t0  ...  ws_100m_t8  \\\n",
       "0        0.249009     1.890047    0.280164    1.400589  ...   -1.132097   \n",
       "1        1.183829     1.408519    0.280164    1.400589  ...   -0.931334   \n",
       "2        1.571044     0.246007    0.280164    1.400589  ...   -0.778698   \n",
       "3        1.183829    -0.916506    0.280164    1.400589  ...   -0.664870   \n",
       "4        0.249009    -1.398034    0.280164    1.400589  ...   -0.452988   \n",
       "...           ...          ...         ...         ...  ...         ...   \n",
       "8315    -0.685811    -0.916506   -0.287572    1.400589  ...   -1.518295   \n",
       "8316    -1.073026     0.246007   -0.287572    1.400589  ...   -1.388240   \n",
       "8317    -1.073026     0.246007   -0.287572    1.400589  ...   -1.439442   \n",
       "8318    -0.685811     1.408519   -0.287572    1.400589  ...   -1.439442   \n",
       "8319     0.249009     1.890047   -0.003704    1.429623  ...   -1.435642   \n",
       "\n",
       "      hour_sin_t8  hour_cos_t8  day_sin_t8  day_cos_t8  month_sin_t8  \\\n",
       "0       -0.685682     1.408711    0.280448    1.400505      0.702453   \n",
       "1        0.249115     1.890286    0.552704    1.314595      0.702453   \n",
       "2        1.183912     1.408711    0.552704    1.314595      0.702453   \n",
       "3        1.571118     0.246088    0.552704    1.314595      0.702453   \n",
       "4        1.183912    -0.916535    0.552704    1.314595      0.702453   \n",
       "...           ...          ...         ...         ...           ...   \n",
       "8315     0.249115    -1.398110   -0.003431    1.429539     -0.019310   \n",
       "8316    -0.685682    -0.916535   -0.003431    1.429539     -0.019310   \n",
       "8317    -1.072887     0.246088   -0.003431    1.429539     -0.019310   \n",
       "8318    -1.072887     0.246088   -0.003431    1.429539     -0.019310   \n",
       "8319    -0.685682     1.408711   -0.003431    1.429539     -0.019310   \n",
       "\n",
       "      month_cos_t8  sin_dayofyear_t8  cos_dayofyear_t8            timestamp  \n",
       "0         1.109234          0.025586          1.291842  2022-01-01 00:00:00  \n",
       "1         1.109234          0.050415          1.291222  2022-01-01 03:00:00  \n",
       "2         1.109234          0.050415          1.291222  2022-01-01 06:00:00  \n",
       "3         1.109234          0.050415          1.291222  2022-01-01 09:00:00  \n",
       "4         1.109234          0.050415          1.291222  2022-01-01 12:00:00  \n",
       "...            ...               ...               ...                  ...  \n",
       "8315      1.295919          0.000749          1.292048  2024-12-30 15:00:00  \n",
       "8316      1.295919          0.000749          1.292048  2024-12-30 18:00:00  \n",
       "8317      1.295919          0.000749          1.292048  2024-12-30 18:00:00  \n",
       "8318      1.295919          0.000749          1.292048  2024-12-30 21:00:00  \n",
       "8319      1.295919          0.000749          1.292048  2024-12-31 00:00:00  \n",
       "\n",
       "[8320 rows x 127 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"output/IT_NORD_VAE_input.csv\")\n",
    "df = df.drop(columns = \"Unnamed: 0\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dataframe Dim: (8320, 90)\n"
     ]
    }
   ],
   "source": [
    "# keeping only dayofthe year\n",
    "features = ['day_sin_t0','day_cos_t0',\n",
    "           'day_sin_t1','day_cos_t1',\n",
    "           'day_sin_t2','day_cos_t2',\n",
    "           'day_sin_t3','day_cos_t3',\n",
    "           'day_sin_t4','day_cos_t4',\n",
    "           'day_sin_t5','day_cos_t5',\n",
    "           'day_sin_t6','day_cos_t6',\n",
    "           'day_sin_t7','day_cos_t7',\n",
    "           'day_sin_t8','day_cos_t8',\n",
    "           'month_sin_t0','month_cos_t0',\n",
    "           'month_sin_t1','month_cos_t1',\n",
    "           'month_sin_t2','month_cos_t2',\n",
    "           'month_sin_t3','month_cos_t3',\n",
    "           'month_sin_t4','month_cos_t4',\n",
    "           'month_sin_t5','month_cos_t5',\n",
    "           'month_sin_t6','month_cos_t6',\n",
    "           'month_sin_t7','month_cos_t7',\n",
    "           'month_sin_t8','month_cos_t8']\n",
    "\n",
    "# in alternative one can use the following lines to keep day and month\n",
    "'''\n",
    "features = ['sin_dayofyear_t0','cos_dayofyear_t0',\n",
    "            'sin_dayofyear_t1','cos_dayofyear_t1',\n",
    "            'sin_dayofyear_t2','cos_dayofyear_t2',\n",
    "            'sin_dayofyear_t3','cos_dayofyear_t3',\n",
    "            'sin_dayofyear_t4','cos_dayofyear_t4',\n",
    "            'sin_dayofyear_t5','cos_dayofyear_t5',\n",
    "            'sin_dayofyear_t6','cos_dayofyear_t6',\n",
    "            'sin_dayofyear_t7','cos_dayofyear_t7',\n",
    "            'sin_dayofyear_t8','cos_dayofyear_t8'\n",
    "            ]\n",
    "'''\n",
    "\n",
    "df = df.drop(columns = features)\n",
    "timestamp = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "timestamp_backup = timestamp.copy()\n",
    "\n",
    "################################################\n",
    "# SOFIA\n",
    "# questo vettore (timestamp) è quello che puoi usare per colorare diversamente i punti secondo un certo criterio\n",
    "# al momento sta usando i dati di produzione di noemi (quelli un po' scrausi)\n",
    "# se vuoi vedere cosa succede per le diverse stagioni puoi provare a cambiare con queste righe:\n",
    "#timestamp = timestamp.dt.hour\n",
    "#timestamp = [1 if x in [1,2,3] else 2 if x in [4,5,6] else 3 if x in [7,8,9] else 4 if x in [10,11,12] for x in timestamp]\n",
    "timestamp = df['2t_t0']\n",
    "# una volta che hai buttato dentro quello che vuoi fai andare il codice (se non va fai andare anche la cella\n",
    "# sopra che c'è un drop qui)\n",
    "##################################################\n",
    "# to save indexes for plotting later\n",
    "timestamp_tensor = torch.tensor(timestamp, dtype = torch.float32)  # Encodes strings to integers\n",
    "\n",
    "df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "print(\"Input Dataframe Dim:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dataframe Dim: (8320, 90)\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset\n",
    "class TabularDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, data_tensor, timestamp_tensor):\n",
    "    self.data = data_tensor\n",
    "    self.timestamp = timestamp_tensor\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index], 0, self.timestamp[index]                              # dummy label for compatibility\n",
    "\n",
    "# Load and preprocess CSV data\n",
    "#df = pd.read_csv(\"IT_NORD_VAE_input.csv\")\n",
    "#df.drop('timestamp', axis=1, inplace=True)\n",
    "print(\"Input Dataframe Dim:\", df.shape)\n",
    "\n",
    "data_tensor = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "# Split the dataset into train, val, test\n",
    "dataset = TabularDataset(data_tensor, timestamp_tensor)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)                               # %80 training, %10 validation and %10 test\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Z_DIM = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z_DIM = 5 | Epoch 1/50: 100%|█| 52/52 [00:00<00:00, 142.28it/s, kl_div=5.33, rec\n",
      "Z_DIM = 5 | Epoch 2/50: 100%|█| 52/52 [00:00<00:00, 159.58it/s, kl_div=7.88, rec\n",
      "Z_DIM = 5 | Epoch 3/50: 100%|█| 52/52 [00:00<00:00, 148.83it/s, kl_div=9.44, rec\n",
      "Z_DIM = 5 | Epoch 4/50: 100%|█| 52/52 [00:00<00:00, 146.45it/s, kl_div=9.64, rec\n",
      "Z_DIM = 5 | Epoch 5/50: 100%|█| 52/52 [00:00<00:00, 168.17it/s, kl_div=10.1, rec\n",
      "Z_DIM = 5 | Epoch 6/50: 100%|█| 52/52 [00:00<00:00, 158.97it/s, kl_div=10.2, rec\n",
      "Z_DIM = 5 | Epoch 7/50: 100%|█| 52/52 [00:00<00:00, 167.93it/s, kl_div=10.5, rec\n",
      "Z_DIM = 5 | Epoch 8/50: 100%|█| 52/52 [00:00<00:00, 171.08it/s, kl_div=10.3, rec\n",
      "Z_DIM = 5 | Epoch 9/50: 100%|█| 52/52 [00:00<00:00, 140.61it/s, kl_div=10.6, rec\n",
      "Z_DIM = 5 | Epoch 10/50: 100%|█| 52/52 [00:00<00:00, 172.33it/s, kl_div=10.4, re\n",
      "Z_DIM = 5 | Epoch 11/50: 100%|█| 52/52 [00:00<00:00, 188.06it/s, kl_div=10.6, re\n",
      "Z_DIM = 5 | Epoch 12/50: 100%|█| 52/52 [00:00<00:00, 157.40it/s, kl_div=10.7, re\n",
      "Z_DIM = 5 | Epoch 13/50: 100%|█| 52/52 [00:00<00:00, 137.26it/s, kl_div=10.2, re\n",
      "Z_DIM = 5 | Epoch 14/50: 100%|█| 52/52 [00:00<00:00, 166.43it/s, kl_div=10.4, re\n",
      "Z_DIM = 5 | Epoch 15/50:   0%| | 0/52 [00:00<?, ?it/s, kl_div=10.5, reconstructi"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "INPUT_DIM = data_tensor.shape[1]\n",
    "H_DIM = 64\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LR_RATE = 1e-3\n",
    "Z_DIM_VALUES = [5]\n",
    "\n",
    "all_histories = {}\n",
    "\n",
    "for Z_DIM in Z_DIM_VALUES:\n",
    "  print(f\"\\nTraining with Z_DIM = {Z_DIM}\")\n",
    "  model = VariationalAutoEncoder(INPUT_DIM, H_DIM, Z_DIM).to(DEVICE)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "  loss_fn = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "  history = {\n",
    "      'total_loss': [],\n",
    "      'reconstruction_loss': [],\n",
    "      'kl_div': [],\n",
    "      'val_total_loss': [],\n",
    "      'val_reconstruction_loss': [],\n",
    "      'val_kl_div': [],\n",
    "      'test_loss': None\n",
    "  }\n",
    "  outputs = []\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    epoch_total = 0\n",
    "    epoch_recon = 0\n",
    "    epoch_kl = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Z_DIM = {Z_DIM} | Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    for i, (x_batch, _, _) in enumerate(loop):\n",
    "      x_batch = x_batch.to(DEVICE)\n",
    "      x_reconstructed, mu, sigma = model(x_batch)\n",
    "\n",
    "      # Loss Function\n",
    "      reconstruction_loss = loss_fn(x_reconstructed, x_batch)\n",
    "      logvar = torch.log(sigma.pow(2) + 1e-8)\n",
    "      kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "      loss = reconstruction_loss + kl_div\n",
    "\n",
    "      # Backpropagation\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loop.set_postfix(\n",
    "          total_loss=loss.item() / x_batch.shape[0],\n",
    "          reconstruction_loss=reconstruction_loss.item() / x_batch.shape[0],\n",
    "          kl_div=kl_div.item() / x_batch.shape[0])\n",
    "\n",
    "      epoch_total += loss.item()\n",
    "      epoch_recon += reconstruction_loss.item()\n",
    "      epoch_kl += kl_div.item()\n",
    "      num_samples += x_batch.shape[0]\n",
    "\n",
    "      if i == 0:\n",
    "        outputs.append((epoch, x_batch.clone(), x_reconstructed.clone()))\n",
    "\n",
    "    # Compute and store averages after each epoch\n",
    "    history['total_loss'].append(epoch_total / num_samples)\n",
    "    history['reconstruction_loss'].append(epoch_recon / num_samples)\n",
    "    history['kl_div'].append(epoch_kl / num_samples)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_total = 0\n",
    "    val_recon = 0\n",
    "    val_kl = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x_val, _ , _ in val_loader:\n",
    "        x_val = x_val.to(DEVICE)\n",
    "        x_reconstructed, mu, sigma = model(x_val)\n",
    "        loss_rec = loss_fn(x_reconstructed, x_val)\n",
    "        logvar = torch.log(sigma.pow(2) + 1e-8)\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = loss_rec + kl_div\n",
    "\n",
    "        val_total += loss.item()\n",
    "        val_recon += loss_rec.item()\n",
    "        val_kl += kl_div.item()\n",
    "        val_samples += x_val.size(0)\n",
    "\n",
    "    history['val_total_loss'].append(val_total / val_samples)\n",
    "    history['val_reconstruction_loss'].append(val_recon / val_samples)\n",
    "    history['val_kl_div'].append(val_kl / val_samples)\n",
    "\n",
    "    # Visualize latent space (t-SNE for high space visualization) (or PCA)\n",
    "    \n",
    "    if (epoch == (NUM_EPOCHS - 1)):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            zs = []\n",
    "            ts = []\n",
    "            for x_batch, _ , timestamp_batch in train_loader:\n",
    "                x_batch = x_batch.to(DEVICE)\n",
    "                mu, sigma = model.encode(x_batch)\n",
    "                zs.append(mu.cpu().numpy())\n",
    "                ts.append(timestamp_batch.numpy())\n",
    "            zs = np.concatenate(zs, axis = 0)\n",
    "            ts = np.concatenate(ts, axis = 0)\n",
    "\n",
    "            # check for unique values\n",
    "            unique_ts = np.unique(ts)\n",
    "            ts_to_idx = {v: i for i, v in enumerate(unique_ts)}\n",
    "            ts_idx = np.array([ts_to_idx[t] for t in ts])\n",
    "\n",
    "            '''# Reduce to 2D\n",
    "            if Z_DIM > 2:\n",
    "                reducer = TSNE(n_components=2, perplexity=30, init='random', random_state=0)\n",
    "                zs_2d = reducer.fit_transform(zs)\n",
    "            else:\n",
    "                zs_2d = zs\n",
    "\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            scatter = plt.scatter(\n",
    "                zs_2d[:, 0], zs_2d[:, 1],\n",
    "                c=ts, cmap='tab20',  # Color by timestamp category\n",
    "                alpha=0.6, s=5\n",
    "            )\n",
    "            plt.colorbar(scatter, label=\"Timestamp Category\")\n",
    "            plt.title(f\"2D Projection of Latent Space at Epoch {epoch + 1} (Z_DIM={Z_DIM})\")\n",
    "            plt.xlabel(\"Component 1\")\n",
    "            plt.ylabel(\"Component 2\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()'''\n",
    "\n",
    "  # Final test set evaluation\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  test_samples = 0\n",
    "  with torch.no_grad():\n",
    "    for x_test, _ , _ in test_loader:\n",
    "      x_test = x_test.to(DEVICE)\n",
    "      x_reconstructed, mu, sigma = model(x_test)\n",
    "      loss_rec = loss_fn(x_reconstructed, x_test)\n",
    "      logvar = torch.log(sigma.pow(2) + 1e-8)\n",
    "      kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "      loss = loss_rec + kl_div\n",
    "      test_loss += loss.item()\n",
    "      test_samples += x_test.shape[0]\n",
    "\n",
    "  history['test_loss'] = test_loss / test_samples\n",
    "  print(f\"Final Test Loss for Z_DIM = {Z_DIM}: {history['test_loss']:.4f}\")\n",
    "\n",
    "  all_histories[Z_DIM] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to use PCA for representing hidden space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Patch\n",
    "import itertools\n",
    "\n",
    "X = zs\n",
    "pca = PCA(n_components = 5)\n",
    "zs_pca = pca.fit_transform(zs)\n",
    "#print(zs_pca.explained_variance_ratio_)\n",
    "print(np.shape(zs_pca))\n",
    "plt.figure(figsize = (7.5, 5))\n",
    "\n",
    "\n",
    "############################\n",
    "# SOFIA\n",
    "# qui ci sono un paio di cose che dovresti ritoccare per i plot\n",
    "# colors handling\n",
    "unique_ts = np.unique(ts)\n",
    "# vengono usati solo i primi n colori (dove n numero di diverse categorie in timestamp\n",
    "custom_colors = ['blue','green', 'orange','#006064','lightblue','#1B5E20', 'green', 'brown','orange','yellow','pink','red','#FFEB3B','#FAF4C4','#FAF4C4',]  \n",
    "keep_colors = custom_colors[:len(unique_ts)]\n",
    "custom_colormap = ListedColormap(custom_colors[:len(unique_ts)])\n",
    "# legend\n",
    "# qui dovresti scrivere a mano a che cosa corrisponde ogni categoria\n",
    "# custom_labels = ['winter','spring','summer','autumn']\n",
    "custom_labels = ['underproduction',\n",
    "                 'balanced',\n",
    "                 'overproduction']\n",
    "#############################\n",
    "#legend_handles = [\n",
    "#    Patch(color=keep_colors[i], label=custom_labels[i]) for i in range(len(unique_ts))\n",
    "#]\n",
    "\n",
    "# Plot all 2D combinations of PCA components\n",
    "combinations = list(itertools.combinations(range(zs_pca.shape[1]), 2))\n",
    "for i, (x_idx, y_idx) in enumerate(combinations):\n",
    "    plt.figure(figsize=(7.5, 5))\n",
    "    \n",
    "    scatter = plt.scatter(zs_pca[:, x_idx], zs_pca[:, y_idx], c=ts, cmap='jet', s=1.4)\n",
    "    \n",
    "    plt.title(f\"PCA Latent Space (Z_DIM = {Z_DIM}) - PC{x_idx+1} vs PC{y_idx+1}\")\n",
    "    plt.xlabel(f\"PC {x_idx+1}\")\n",
    "    plt.ylabel(f\"PC {y_idx+1}\")\n",
    "    #plt.legend(handles=legend_handles, title=\"Classes\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.colorbar(label='Normalized solar progression')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"PCA_output/ZDIM_{Z_DIM}_PC{x_idx}_{y_idx}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=False)\n",
    "ymin, ymax = 0, 140\n",
    "\n",
    "# Plot of Total Loss\n",
    "for z_dim, history in all_histories.items():\n",
    "  axs[0].plot(history['total_loss'], label=f\"Z_DIM = {z_dim}\")\n",
    "  axs[0].set_ylabel(\"Total Loss\")\n",
    "  axs[0].set_xlabel(\"Epoch\")\n",
    "  axs[0].set_title(\"Total Loss Across Epochs\")\n",
    "  axs[0].set_ylim(ymin, ymax)\n",
    "  axs[0].legend()\n",
    "  axs[0].grid(True)\n",
    "\n",
    "# Plot of Reconstruction Loss\n",
    "for z_dim, history in all_histories.items():\n",
    "  axs[1].plot(history['reconstruction_loss'], label=f\"Z_DIM = {z_dim}\")\n",
    "  axs[1].set_ylabel(\"Reconstruction Loss\")\n",
    "  axs[1].set_xlabel(\"Epoch\")\n",
    "  axs[1].set_title(\"Reconstruction Loss Across Epochs\")\n",
    "  axs[1].set_ylim(ymin, ymax)\n",
    "  axs[1].legend()\n",
    "  axs[1].grid(True)\n",
    "\n",
    "# Plot of KL Divergence\n",
    "for z_dim, history in all_histories.items():\n",
    "  axs[2].plot(history['kl_div'], label=f\"Z_DIM = {z_dim}\")\n",
    "  axs[2].set_xlabel(\"Epoch\")\n",
    "  axs[2].set_ylabel(\"KL Divergence\")\n",
    "  axs[2].set_title(\"KL Divergence Across Epochs\")\n",
    "  axs[2].set_ylim(ymin, ymax)\n",
    "  axs[2].legend()\n",
    "  axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Z_DIM':<8} {'Total Loss':<13} {'Recon Loss':<13} {'KL-Divergence':<13}\")\n",
    "for z_dim, history in all_histories.items():\n",
    "  print(f\"{z_dim:<8} {history['total_loss'][-1]:<13.2f} {history['reconstruction_loss'][-1]:<13.2f} {history['kl_div'][-1]:<13.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2t7GlakP1OHh5OIpdvKQX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
